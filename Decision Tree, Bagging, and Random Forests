'''Classify the variable species in the Penguins dataset, using decision tree, bagging, and random forests. 
   Import tree from sklearn package to help implement the algorithms.'''
    
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.tree import plot_tree
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier
import warnings
warnings.filterwarnings("ignore")
from mlxtend.evaluate import bias_variance_decomp

# 1. Decision Tree
# Step 1 Data preprocessing
data = pd.read_csv(r"C:\Users\谭兆宏\Desktop\penguins.csv")
data = data.dropna()        # drop data lines which contain 'NaN'
for titles in data:
    value_list = list(data[titles].unique())
    if type(value_list[0]) == str:
        print(titles, value_list)
#Converting str data to int data for analysis
species_label = {'Adelie':0, 'Chinstrap':1, 'Gentoo':2}
island_label = {'Torgersen':0, 'Biscoe':1, 'Dream':2}
sex_label = {'MALE':1, 'FEMALE':0}
data['species'] = data['species'].map(species_label)
data['island'] = data['island'].map(island_label)
data['sex'] = data['sex'].map(sex_label)
x_list, y_list = [], []
for spe in data['species']:
    y_list.append(spe)
island, bill_length_mm,  bill_depth_mm,  flipper_length_mm, body_mass_g, sex = list(data['island']), \
        list(data['bill_length_mm']), list(data['bill_depth_mm']), list(data['flipper_length_mm']), \
        list(data['body_mass_g']), list(data['sex'])
for index in range(len(island)):
    x_list.append([island[index], bill_length_mm[index], bill_depth_mm[index],
                   flipper_length_mm[index], body_mass_g[index], sex[index]])
X_train, X_test, y_train, y_test = train_test_split(x_list, y_list, test_size=0.25)

# Step 2 Data statistics
for titles in data:
    plt.hist(data[titles], bins=10)
    plt.xlabel(titles)
    plt.ylabel('rate')
    plt.show()

# Step 3 Decision tree
def decision_tree(x_tra, x_tes, y_tra, y_tes, maxi_dep, least_node_size):
    clf = tree.DecisionTreeClassifier(max_depth=maxi_dep, min_samples_leaf=least_node_size, criterion='entropy')
    clf = clf.fit(x_tra, y_tra)
    train_accuracy = clf.score(x_tra, y_tra)
    test_accuracy = clf.score(x_tes, y_tes)
    plt.figure(figsize=(5,3))
    plot_tree(clf, filled=True)
    plt.show()
    return [train_accuracy, test_accuracy]
for max_dep in [2, 4, 6]:
    for least_node_sizes in [3, 6, 9]:
        print('The current max_depth is', max_dep, 'The current least node size is', least_node_sizes)
        accuracy = decision_tree(X_train, X_test, y_train, y_test, max_dep, least_node_sizes)
        print('The training accuracy is:', accuracy[0])
        print('The testing accuracy is:', accuracy[1])

# Step 4 Bagging of trees
def bagging_decision_tree(x_tra, x_tes, y_tra, y_tes, maxi_dep, num_of_trees):
    dt = tree.DecisionTreeClassifier(max_depth=maxi_dep)
    clf_bagg = BaggingClassifier(base_estimator=dt, n_estimators=num_of_trees, random_state=0)
    clf_bagg.fit(x_tra, y_tra)
    train_accuracy = clf_bagg.score(x_tra, y_tra)
    test_accuracy = clf_bagg.score(x_tes, y_tes)
    return [train_accuracy, test_accuracy]
for max_dep in [2, 4, 6]:
    for num in [3, 10, 20]:
        print('The current max_depth is', max_dep, 'The current number of trees is', num)
        accuracy_bagg = bagging_decision_tree(X_train, X_test, y_train, y_test, max_dep, num)
        print('The training accuracy is:', accuracy_bagg[0])
        print('The testing accuracy is:', accuracy_bagg[1])

# Step 5 Random forest
def random_forest(x_tra, x_tes, y_tra, y_tes, num_of_trees, value_of_m):
    clf_random_forest = RandomForestClassifier(random_state=0, n_estimators=num_of_trees,
                                               min_samples_split=value_of_m, max_depth=8)
    clf_random_forest.fit(x_tra, y_tra)
    train_accuracy = clf_random_forest.score(x_tra, y_tra)
    test_accuracy = clf_random_forest.score(x_tes, y_tes)
    return [train_accuracy, test_accuracy]
for m in [2, 4, 6]:
    for num in [3, 10, 20]:
        print('The current number of trees is', num, 'The current value of m is', m)
        accuracy_random_forest = random_forest(X_train, X_test, y_train, y_test, num, m)
        print('The training accuracy is:', accuracy_random_forest[0])
        print('The testing accuracy is:', accuracy_random_forest[1])

# Step 6 plot
bias_square = []
num_of_trees = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
for num in num_of_trees:
    clf_r_f = RandomForestClassifier(random_state=0, n_estimators=num, max_depth=8)
    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)
    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(clf_r_f, X_train, y_train, X_test, y_test, loss='mse')
    bias_square.append(np.square(avg_bias))
plt.xlabel('Number of trees')
plt.ylabel('bias^2')
plt.plot(num_of_trees, bias_square)
plt.show()
